{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303773b0",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# Feature Engineering (Signal Construction)\n",
    "\n",
    "This notebook is responsible for converting raw company attributes into\n",
    "meaningful numerical signals for clustering.\n",
    "\n",
    "⚠️ Scope:\n",
    "- No data cleaning or missing-value decisions are made here\n",
    "- All logic assumes a future `clean_base.csv` produced by Member 1\n",
    "- Raw data is used temporarily for feature design only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037a1a0a",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Display all columns during inspection (feature-heavy dataset)\n",
    "pd.set_option(\"display.max_columns\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b289b8",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# TEMPORARY STEP\n",
    "# Raw data is loaded ONLY to understand column structure\n",
    "# and prototype feature transformations.\n",
    "# This will later be replaced with Member 1's clean_base.csv.\n",
    "\n",
    "df_raw= pd.read_csv('../data/champions_group_data.csv')\n",
    "\n",
    "# Inspect dataset shape and column names\n",
    "df_raw.shape, df_raw.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c4bcaea",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# Transparency-related signals\n",
    "\n",
    "# 1 if the company has a website listed, 0 otherwise\n",
    "# captures basic online presence and legitimacy\n",
    "df_raw[\"has_website\"] = df_raw[\"Website\"].notna().astype(int)\n",
    "\n",
    "# 1 if a phone number is available, 0 otherwise\n",
    "# Absence may indicate low transparency or early-stage entities\n",
    "df_raw[\"has_phone\"] = df_raw[\"Phone Number\"].notna().astype(int)\n",
    "\n",
    "# 1 if a physical address is listed, 0 otherwise\n",
    "# Used as a proxy for operational traceability\n",
    "df_raw[\"has_address\"] = df_raw[\"Address Line 1\"].notna().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aa90b4",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# Ownership / structural signals\n",
    "# Capture organisational complexity.\n",
    "# Complex ownership structures often correlate with higher monitoring\n",
    "# and compliance risk in real-world company analysis.\n",
    "\n",
    "# Indicates whether a parent company is recorded\n",
    "df_raw[\"has_parent\"] = df_raw[\"Parent Company\"].notna().astype(int)\n",
    "\n",
    "# Indicates whether a global ultimate owner is recorded\n",
    "# Global ultimate entities suggest multinational structures\n",
    "df_raw[\"has_global_ultimate\"] = df_raw[\"Global Ultimate Company\"].notna().astype(int)\n",
    "\n",
    "# Indicates whether a domestic ultimate owner is recorded\n",
    "df_raw[\"has_domestic_ultimate\"] = df_raw[\"Domestic Ultimate Company\"].notna().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc0b9fa4",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Organisational complexity signal\n",
    "# Idea: companies that share the same \"Global Ultimate Company\" belong to the same corporate group.\n",
    "# We define organisational complexity as the size of that group (number of companies in the dataset\n",
    "# that roll up to the same global ultimate).\n",
    "\n",
    "# Note:\n",
    "# We must avoid treating missing global ultimate as one giant group.\n",
    "# So missing values get a count of 0 (or 1 if you prefer \"unknown but standalone\").\n",
    "# We also standardize names (strip whitespace, upper-case) to reduce duplicates caused by formatting.\n",
    "\n",
    "# 1 Create a standardized key for grouping (prevents \"ABC LTD\" vs \" ABC LTD \" being treated differently)\n",
    "df_raw[\"global_ultimate_key\"] = (\n",
    "    df_raw[\"Global Ultimate Company\"]\n",
    "    .astype(\"string\")          # ensure consistent string dtype\n",
    "    .str.strip()               # remove leading/trailing spaces\n",
    "    .str.upper()               # normalize casing\n",
    ")\n",
    "\n",
    "# 2  Count how many rows share the same global ultimate key\n",
    "# transform(\"size\") returns a series aligned with original rows (same length as df_raw)\n",
    "group_sizes = df_raw.groupby(\"global_ultimate_key\")[\"global_ultimate_key\"].transform(\"size\")\n",
    "\n",
    "# 3 Assign organisational complexity count\n",
    "# For missing global ultimate, set to 0 so \"unknown ultimate\" doesn't become an artificial mega-group\n",
    "df_raw[\"org_complexity_count\"] = np.where(\n",
    "    df_raw[\"global_ultimate_key\"].notna(),\n",
    "    group_sizes,\n",
    "    0\n",
    ")\n",
    "print(min(df_raw[\"org_complexity_count\"] ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "169b85bc",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# Scale-related signals\n",
    "# Raw size metrics (employees, revenue) are heavily skewed.\n",
    "# Log-transforming prevents large firms from dominating\n",
    "# distance-based clustering.\n",
    "# Log-transform total employee count\n",
    "# log1p(x)=ln(1+x) to handle zeroes \n",
    "df_raw[\"log_employees_total\"] = np.log1p(df_raw[\"Employees Total\"])\n",
    "df_raw[\"log_revenue_usd\"] = np.log1p(df_raw[\"Revenue (USD)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f08d0992",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# Operational footprint signals\n",
    "# Some IT-related columns are stored as ranges (e.g. \"1 to 10\").\n",
    "# These are converted into numeric midpoints to enable comparison.\n",
    "\n",
    "def range_to_midpoint(value):\n",
    "\n",
    "    if isinstance(value, str) and \"to\" in value:\n",
    "        low, high = value.split(\"to\")\n",
    "        return (float(low.strip()) + float(high.strip())) / 2\n",
    "    return np.nan\n",
    "\n",
    "# Apply midpoint conversion to IT-related columns \n",
    "df_raw[\"servers_midpoint\"] = df_raw[\"No. of Servers\"].apply(range_to_midpoint)\n",
    "df_raw[\"desktops_midpoint\"] = df_raw[\"No. of Desktops\"].apply(range_to_midpoint)\n",
    "df_raw[\"routers_midpoint\"] = df_raw[\"No. of Routers\"].apply(range_to_midpoint)\n",
    "df_raw[\"storage_devices_midpoint\"] = df_raw[\"No. of Storage Devices\"].apply(range_to_midpoint)\n",
    "df_raw[\"pc_midpoint\"] = df_raw[\"No. of PC\"].apply(range_to_midpoint)\n",
    "df_raw[\"laptops_midpoint\"] = df_raw[\"No. of Laptops\"].apply(range_to_midpoint)\n",
    "\n",
    "# Total endpoint count (treat NaNs as 0 for the sum; keep missing flags separately if you want)\n",
    "it_assets = [\"desktops_midpoint\", \"laptops_midpoint\", \"pc_midpoint\", \"servers_midpoint\", \"routers_midpoint\", \"storage_devices_midpoint\"]\n",
    "df_raw[\"it_assets_total\"] = df_raw[it_assets].fillna(0).sum(axis=1)\n",
    "\n",
    "# Log-transform to reduce domination by firms with very large counts\n",
    "df_raw[\"log_it_assets_total\"] = np.log1p(df_raw[\"it_assets_total\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8aa919",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# IT Budget / Spend signals\n",
    "# it_spend_rate = IT Spend / IT Budget (efficiency / execution)\n",
    "# budget_minus_spend = IT Budget - IT Spend (underspend/overspend)\n",
    "# -------------------------------\n",
    "\n",
    "# Coerce to numeric safely (handles strings, commas; non-parsable -> NaN)\n",
    "df_raw[\"it_budget\"] = pd.to_numeric(df_raw[\"IT Budget\"], errors=\"coerce\")\n",
    "df_raw[\"it_spend\"]  = pd.to_numeric(df_raw[\"IT spend\"], errors=\"coerce\")\n",
    "\n",
    "# Log transforms for clustering stability\n",
    "df_raw[\"log_it_budget\"] = np.log1p(df_raw[\"it_budget\"])\n",
    "df_raw[\"log_it_spend\"]  = np.log1p(df_raw[\"it_spend\"])\n",
    "\n",
    "# Spend rate: how much of budget is actually spent\n",
    "df_raw[\"it_spend_rate\"] = df_raw[\"it_spend\"] / df_raw[\"it_budget\"]\n",
    "\n",
    "# Keep spend rate bounded (optional but useful)\n",
    "df_raw[\"it_spend_rate\"] = df_raw[\"it_spend_rate\"].clip(lower=0, upper=3)\n",
    "\n",
    "# Budget gap: positive = under-spending, negative = overspending\n",
    "df_raw[\"it_budget_gap\"] = df_raw[\"it_budget\"] - df_raw[\"it_spend\"]\n",
    "df_raw[\"log_abs_it_budget_gap\"] = np.log1p(df_raw[\"it_budget_gap\"].abs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6e809eb",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# IT intensity per employee (size-normalized)\n",
    "\n",
    "# Ensure employees are numeric; if you already have Employees Total numeric, use that\n",
    "employees = pd.to_numeric(df_raw[\"Employees Total\"], errors=\"coerce\")\n",
    "\n",
    "# Avoid divide-by-zero and nonsense: only compute where employees > 0\n",
    "mask_emp = employees > 0\n",
    "\n",
    "df_raw[\"it_assets_per_employee\"] = np.nan\n",
    "df_raw.loc[mask_emp, \"it_assets_per_employee\"] = df_raw.loc[mask_emp, \"it_assets_total\"] / employees[mask_emp]\n",
    "\n",
    "df_raw[\"it_spend_per_employee\"] = np.nan\n",
    "df_raw.loc[mask_emp, \"it_spend_per_employee\"] = df_raw.loc[mask_emp, \"it_spend\"] / employees[mask_emp]\n",
    "\n",
    "# Log to reduce heavy tails\n",
    "df_raw[\"log_it_assets_per_employee\"] = np.log1p(df_raw[\"it_assets_per_employee\"])\n",
    "df_raw[\"log_it_spend_per_employee\"] = np.log1p(df_raw[\"it_spend_per_employee\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "67ff3688",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# Server-centric vs endpoint-centric ratio\n",
    "# This helps separate: infrastructure-heavy orgs (servers/storage)\n",
    "# vs office/endpoint-heavy orgs (PC/laptops/desktops)\n",
    "\n",
    "# IT composition ratios\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# IT composition ratios\n",
    "# -------------------------------\n",
    "\n",
    "endpoint_total = df_raw[[\"desktops_midpoint\", \"laptops_midpoint\", \"pc_midpoint\"]].fillna(0).sum(axis=1)\n",
    "infra_total = df_raw[[\"servers_midpoint\", \"storage_devices_midpoint\", \"routers_midpoint\"]].fillna(0).sum(axis=1)\n",
    "\n",
    "# Add small epsilon to avoid division by zero\n",
    "eps = 1e-9\n",
    "\n",
    "df_raw[\"infra_to_endpoint_ratio\"] = infra_total / (endpoint_total + eps)\n",
    "df_raw[\"log_infra_to_endpoint_ratio\"] = np.log1p(df_raw[\"infra_to_endpoint_ratio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e753e85e",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# IT reporting completeness\n",
    "\n",
    "it_raw_cols = [\n",
    "    \"No. of Desktops\", \"No. of Laptops\", \"No. of Routers\", \"No. of Servers\",\n",
    "    \"No. of Storage Devices\", \"No. of PC\", \"IT Budget\", \"IT spend\"\n",
    "]\n",
    "\n",
    "# 1 if non-missing and not empty\n",
    "it_trimmed = df_raw[it_raw_cols].apply(lambda s: s.astype(\"string\").str.strip())\n",
    "df_raw[\"it_reporting_score\"] = (it_trimmed.notna() & it_trimmed.ne(\"\")).sum(axis=1)\n",
    "\n",
    "df_raw[\"it_reporting_score_norm\"] = df_raw[\"it_reporting_score\"] / len(it_raw_cols)\n",
    "df_raw[\"it_missing_ratio\"] = 1 - df_raw[\"it_reporting_score_norm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1675ae1",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# Credible + IT-heavy interaction\n",
    "# Sometimes clusters form like:\n",
    "# high credibility + high IT footprint (mature corp)\n",
    "# low credibility + low IT footprint (small/opaque)\n",
    "# high credibility + low IT footprint (traditional industries)\n",
    "\n",
    "\n",
    "# Interaction features (optional)\n",
    "df_raw[\"cred_x_log_it_assets\"] = df_raw[\"credibility_score_norm\"] * df_raw[\"log_it_assets_total\"]\n",
    "df_raw[\"cred_x_log_it_spend\"]  = df_raw[\"credibility_score_norm\"] * df_raw[\"log_it_spend\"]\n",
    "\n",
    "df_raw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa16fb3",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# Credibility/missingness \n",
    "df_raw[\"has_ticker\"] = df_raw[\"Ticker\"].notna().astype(int)\n",
    "df_raw[\"has_registration_number\"] = df_raw[\"Registration Number\"].notna().astype(int)\n",
    "df_raw[\"has_company_description\"] = df_raw[\"Company Description\"].notna().astype(int)\n",
    "status_col = \"Company Status (Active/Inactive)\"\n",
    "df_raw[\"company_status_binary\"] = (\n",
    "    df_raw[status_col]\n",
    "    .astype(\"string\")\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .map({\"active\": 1, \"inactive\": 0})\n",
    ")\n",
    "\n",
    "credibility_flag_cols = [\n",
    "    \"has_website\",\n",
    "    \"has_address\",\n",
    "    \"has_phone\",\n",
    "    \"has_ticker\",\n",
    "    \"has_parent\",\n",
    "    \"has_global_ultimate\",\n",
    "    \"has_domestic_ultimate\",\n",
    "    \"has_registration_number\",\n",
    "    \"has_company_description\",\n",
    "    \"company_status_binary\"]\n",
    "\n",
    "# credibility score = how many verifiability fields are present\n",
    "df_raw[\"credibility_score\"] = df_raw[credibility_flag_cols].sum(axis=1)\n",
    "\n",
    "# normalized to 0..1\n",
    "df_raw[\"credibility_score_norm\"] = df_raw[\"credibility_score\"] / len(credibility_flag_cols)\n",
    "\n",
    "# missing_ratio = inverse of credibility\n",
    "df_raw[\"missing_ratio\"] = 1 - df_raw[\"credibility_score_norm\"]\n",
    "df_raw.head(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "deeb1707",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# Encoding categorical variables\n",
    "# Low-cardinality categorical variables are one-hot encoded\n",
    "# to allow distance-based clustering to treat categories distinctly.\n",
    "categorical_cols = [\"Region\", \"Entity Type\", \"Ownership Type\"]\n",
    "\n",
    "# One-hot encode selected categorical columns\n",
    "df_encoded = pd.get_dummies(df_raw, columns=categorical_cols, drop_first=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
