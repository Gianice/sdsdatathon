{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63f0b0fb",
   "metadata": {},
   "source": [
    "# Member 2 â€” Feature Engineering (Signal Construction)\n",
    "\n",
    "**Goal:** Turn company attributes into **numeric, comparable, explainable signals** for **PCA + clustering**.\n",
    "\n",
    "**Scope (Member 2):**\n",
    "- Start from **Member 1's cleaned & imputed dataset** (recommended: `data/processed/clean_base.csv`).\n",
    "- Do **not** make global cleaning decisions (dropping rows/columns, global imputation strategies, etc.).\n",
    "- You *may* create **presence indicators** and derived features that treat missingness as signal.\n",
    "\n",
    "**Outputs (for handoff):**\n",
    "- `df_features_raw`: numeric feature matrix (not scaled)\n",
    "- `df_features_scaled`: scaled matrix for PCA/clustering\n",
    "- `feature_dict`: short description of engineered features\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "580538a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pd.set_option('display.max_columns', 250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a83d3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: ../data/champions_group_data.csv\n",
      "Shape: (8559, 72)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yeow mun hung\\AppData\\Local\\Temp\\ipykernel_9400\\1244267380.py:15: DtypeWarning: Columns (26,49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(RAW_FALLBACK)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Load data\n",
    "# -------------------------------\n",
    "# Prefer Member 1's output (cleaned & imputed). Fallback to raw for sandboxing.\n",
    "\n",
    "import os\n",
    "\n",
    "CLEAN_PATH = '../data/processed/clean_base.csv'\n",
    "RAW_FALLBACK = '../data/champions_group_data.csv'\n",
    "\n",
    "if os.path.exists(CLEAN_PATH):\n",
    "    df = pd.read_csv(CLEAN_PATH)\n",
    "    data_source = CLEAN_PATH\n",
    "else:\n",
    "    df = pd.read_csv(RAW_FALLBACK)\n",
    "    data_source = RAW_FALLBACK\n",
    "\n",
    "print('Loaded:', data_source)\n",
    "print('Shape:', df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd6362f",
   "metadata": {},
   "source": [
    "## 1) Helper functions\n",
    "\n",
    "We standardize \"presence\" checks so empty strings don't count as filled.\n",
    "We also parse range strings like `\"1 to 10\"` into numeric midpoints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82f63b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_value(series: pd.Series) -> pd.Series:\n",
    "    # True if non-missing AND not empty/whitespace\n",
    "    s = series.astype('string').str.strip()\n",
    "    return s.notna() & s.ne('')\n",
    "\n",
    "\n",
    "def range_to_midpoint(value):\n",
    "    # Convert 'x to y' -> midpoint; return NaN otherwise\n",
    "    if isinstance(value, str) and 'to' in value:\n",
    "        low, high = value.split('to')\n",
    "        try:\n",
    "            return (float(low.strip()) + float(high.strip())) / 2\n",
    "        except ValueError:\n",
    "            return np.nan\n",
    "    return np.nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81d30dc",
   "metadata": {},
   "source": [
    "## 2) Core transparency + structure signals (curated short names)\n",
    "\n",
    "These are your **interpretable, low-risk** binary signals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6667ed8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transparency / traceability\n",
    "\n",
    "df['has_website'] = has_value(df['Website']).astype(int)\n",
    "df['has_phone']   = has_value(df['Phone Number']).astype(int)\n",
    "df['has_address'] = has_value(df['Address Line 1']).astype(int)\n",
    "\n",
    "# Ownership / structure\n",
    "\n",
    "df['has_parent']           = has_value(df['Parent Company']).astype(int)\n",
    "df['has_global_ultimate']  = has_value(df['Global Ultimate Company']).astype(int)\n",
    "df['has_domestic_ultimate']= has_value(df['Domestic Ultimate Company']).astype(int)\n",
    "\n",
    "# Verifiability extras\n",
    "\n",
    "df['has_ticker'] = has_value(df['Ticker']).astype(int)\n",
    "df['has_registration_number'] = has_value(df['Registration Number']).astype(int)\n",
    "df['has_company_description'] = has_value(df['Company Description']).astype(int)\n",
    "\n",
    "# Company status (value-coded)\n",
    "status_col = 'Company Status (Active/Inactive)'\n",
    "df['company_status_binary'] = (\n",
    "    df[status_col].astype('string').str.strip().str.lower().map({'active': 1, 'inactive': 0})\n",
    ")\n",
    "# Presence of status (for completeness scoring)\n",
    "df['has_company_status'] = df['company_status_binary'].notna().astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121dbe6f",
   "metadata": {},
   "source": [
    "## 3) Credibility / completeness score (and missing_ratio)\n",
    "\n",
    "We include **status-known** (not status value) so inactive firms aren't penalized.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0940bc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "credibility_flag_cols = [\n",
    "    'has_website', 'has_address', 'has_phone',\n",
    "    'has_ticker', 'has_parent', 'has_global_ultimate', 'has_domestic_ultimate',\n",
    "    'has_registration_number', 'has_company_description',\n",
    "    'has_company_status'\n",
    "]\n",
    "\n",
    "# Completeness score: how many key fields are filled\n",
    "\n",
    "df['credibility_score'] = df[credibility_flag_cols].sum(axis=1)\n",
    "df['credibility_score_norm'] = df['credibility_score'] / len(credibility_flag_cols)\n",
    "\n",
    "# Missingness proxy: higher = more opaque record\n",
    "\n",
    "df['missing_ratio'] = 1 - df['credibility_score_norm']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e912d95",
   "metadata": {},
   "source": [
    "## 4) Organisational complexity (group size by global ultimate)\n",
    "\n",
    "Companies sharing the same global ultimate are treated as belonging to the same group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dc1bc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['global_ultimate_key'] = (\n",
    "    df['Global Ultimate Company'].astype('string').str.strip().str.upper()\n",
    ")\n",
    "\n",
    "# Group size (aligned to rows)\n",
    "group_sizes = df.groupby('global_ultimate_key')['global_ultimate_key'].transform('size')\n",
    "\n",
    "# Avoid treating missing global ultimate as one mega-group\n",
    "\n",
    "df['org_complexity_count'] = np.where(df['global_ultimate_key'].notna(), group_sizes, 0)\n",
    "df['log_org_complexity_count'] = np.log1p(df['org_complexity_count'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e50d35",
   "metadata": {},
   "source": [
    "## 5) Scale + market signals\n",
    "\n",
    "These control for size so clustering isn't just \"big vs small\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47045713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coerce likely numeric fields\n",
    "\n",
    "for col in ['Employees Single Site', 'Employees Total', 'Revenue (USD)', 'Market Value (USD)', 'Company Sites', 'Corporate Family Members', 'Year Found']:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Log transforms\n",
    "\n",
    "df['log_employees_total'] = np.log1p(df['Employees Total'])\n",
    "df['log_employees_single_site'] = np.log1p(df['Employees Single Site'])\n",
    "df['log_revenue_usd'] = np.log1p(df['Revenue (USD)'])\n",
    "\n",
    "df['log_market_value_usd'] = np.log1p(df['Market Value (USD)'])\n",
    "df['log_company_sites'] = np.log1p(df['Company Sites'])\n",
    "df['log_corporate_family_members'] = np.log1p(df['Corporate Family Members'])\n",
    "\n",
    "# Company age\n",
    "CURRENT_YEAR = 2026\n",
    "\n",
    "df['company_age'] = CURRENT_YEAR - df['Year Found']\n",
    "# Clamp impossible ages to NaN (Member 1 should have cleaned, but this is a safety net)\n",
    "df.loc[(df['company_age'] < 0) | (df['company_age'] > 300), 'company_age'] = np.nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3332bd",
   "metadata": {},
   "source": [
    "## 6) Geography + multinational heuristics\n",
    "\n",
    "We avoid one-hot encoding high-cardinality city names. Use country/region + parent/ultimate country comparisons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "105bf6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinates are useful for PCA/clustering if available\n",
    "for col in ['Lattitude', 'Longitude']:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Multinational flags: compare entity country to parent/ultimate country\n",
    "\n",
    "def normalized_country(series):\n",
    "    return series.astype('string').str.strip().str.upper()\n",
    "\n",
    "entity_country = normalized_country(df['Country'])\n",
    "parent_country = normalized_country(df['Parent Country/Region'])\n",
    "global_country = normalized_country(df['Global Ultimate Country Name'])\n",
    "\n",
    "df['parent_foreign_flag'] = ((df['has_parent'] == 1) & (parent_country.ne('') ) & (parent_country != entity_country)).astype(int)\n",
    "df['global_ultimate_foreign_flag'] = ((df['has_global_ultimate'] == 1) & (global_country.ne('')) & (global_country != entity_country)).astype(int)\n",
    "\n",
    "df['multinational_flag'] = ((df['parent_foreign_flag'] == 1) | (df['global_ultimate_foreign_flag'] == 1)).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14adc695",
   "metadata": {},
   "source": [
    "## 7) IT / operational footprint signals\n",
    "\n",
    "We parse IT asset ranges into midpoints, then build intensity & composition signals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "175e80b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Midpoints for range-like IT asset fields\n",
    "\n",
    "df['pc_midpoint'] = df['No. of PC'].apply(range_to_midpoint)\n",
    "df['desktops_midpoint'] = df['No. of Desktops'].apply(range_to_midpoint)\n",
    "df['laptops_midpoint'] = df['No. of Laptops'].apply(range_to_midpoint)\n",
    "df['routers_midpoint'] = df['No. of Routers'].apply(range_to_midpoint)\n",
    "df['servers_midpoint'] = df['No. of Servers'].apply(range_to_midpoint)\n",
    "df['storage_devices_midpoint'] = df['No. of Storage Devices'].apply(range_to_midpoint)\n",
    "\n",
    "it_assets = ['pc_midpoint', 'desktops_midpoint', 'laptops_midpoint', 'routers_midpoint', 'servers_midpoint', 'storage_devices_midpoint']\n",
    "\n",
    "df['it_assets_total'] = df[it_assets].fillna(0).sum(axis=1)\n",
    "df['log_it_assets_total'] = np.log1p(df['it_assets_total'])\n",
    "\n",
    "# IT Budget / Spend\n",
    "\n",
    "df['it_budget'] = pd.to_numeric(df['IT Budget'], errors='coerce')\n",
    "df['it_spend']  = pd.to_numeric(df['IT spend'], errors='coerce')\n",
    "\n",
    "df['log_it_budget'] = np.log1p(df['it_budget'])\n",
    "df['log_it_spend']  = np.log1p(df['it_spend'])\n",
    "\n",
    "df['it_spend_rate'] = (df['it_spend'] / df['it_budget']).clip(lower=0, upper=3)\n",
    "df['it_budget_gap'] = df['it_budget'] - df['it_spend']\n",
    "df['log_abs_it_budget_gap'] = np.log1p(df['it_budget_gap'].abs())\n",
    "\n",
    "# Intensity per employee (size-normalized)\n",
    "emp = df['Employees Total']\n",
    "mask_emp = emp > 0\n",
    "\n",
    "df['it_assets_per_employee'] = np.nan\n",
    "df.loc[mask_emp, 'it_assets_per_employee'] = df.loc[mask_emp, 'it_assets_total'] / emp[mask_emp]\n",
    "\n",
    "df['it_spend_per_employee'] = np.nan\n",
    "df.loc[mask_emp, 'it_spend_per_employee'] = df.loc[mask_emp, 'it_spend'] / emp[mask_emp]\n",
    "\n",
    "df['log_it_assets_per_employee'] = np.log1p(df['it_assets_per_employee'])\n",
    "df['log_it_spend_per_employee'] = np.log1p(df['it_spend_per_employee'])\n",
    "\n",
    "# Composition: infrastructure vs endpoints\n",
    "endpoint_total = df[['desktops_midpoint', 'laptops_midpoint', 'pc_midpoint']].fillna(0).sum(axis=1)\n",
    "infra_total = df[['servers_midpoint', 'storage_devices_midpoint', 'routers_midpoint']].fillna(0).sum(axis=1)\n",
    "\n",
    "eps = 1e-9\n",
    "\n",
    "df['infra_to_endpoint_ratio'] = infra_total / (endpoint_total + eps)\n",
    "df['log_infra_to_endpoint_ratio'] = np.log1p(df['infra_to_endpoint_ratio'])\n",
    "\n",
    "# IT reporting completeness (how many IT fields are present)\n",
    "it_raw_cols = [\n",
    "    'No. of Desktops', 'No. of Laptops', 'No. of Routers', 'No. of Servers',\n",
    "    'No. of Storage Devices', 'No. of PC', 'IT Budget', 'IT spend'\n",
    "]\n",
    "\n",
    "df_it_trimmed = df[it_raw_cols].apply(lambda s: s.astype('string').str.strip())\n",
    "df['it_reporting_score'] = (df_it_trimmed.notna() & df_it_trimmed.ne('')).sum(axis=1)\n",
    "df['it_reporting_score_norm'] = df['it_reporting_score'] / len(it_raw_cols)\n",
    "df['it_missing_ratio'] = 1 - df['it_reporting_score_norm']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed800dd",
   "metadata": {},
   "source": [
    "## 8) Industry code features (low-cardinality sector buckets)\n",
    "\n",
    "Full industry codes can be high-cardinality. For clustering/PCA, we use **2-digit buckets** (industry sectors).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8766c744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_prefix(series, n=2):\n",
    "    # Convert codes to strings and take first n digits/characters\n",
    "    s = series.astype('string').str.strip()\n",
    "    # Keep digits only (common for codes)\n",
    "    s = s.str.replace(r'\\D+', '', regex=True)\n",
    "    return s.str[:n]\n",
    "\n",
    "# 2-digit buckets (safe for PCA/clustering)\n",
    "\n",
    "df['sic2'] = code_prefix(df['SIC Code'], n=2)\n",
    "df['naics2'] = code_prefix(df['NAICS Code'], n=2)\n",
    "df['nace2'] = code_prefix(df['NACE Rev 2 Code'], n=2)\n",
    "df['anzsic2'] = code_prefix(df['ANZSIC Code'], n=2)\n",
    "df['isic2'] = code_prefix(df['ISIC Rev 4 Code'], n=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b925e2b3",
   "metadata": {},
   "source": [
    "## 9) Categorical encoding (PCA/clustering ready)\n",
    "\n",
    "We one-hot encode selected low-cardinality categoricals + sector buckets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f1af319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After encoding: (8559, 422)\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = [\n",
    "    'Region', 'Entity Type', 'Ownership Type',\n",
    "    'Legal Status', 'Franchise Status', 'Manufacturing Status',\n",
    "    'Is Headquarters', 'Is Domestic Ultimate',\n",
    "    'Registration Number Type',\n",
    "    'sic2', 'naics2', 'nace2', 'anzsic2', 'isic2'\n",
    "]\n",
    "\n",
    "# Convert booleans/flags that may be stored as strings\n",
    "for col in ['Is Headquarters', 'Is Domestic Ultimate']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype('string').str.strip().str.lower().map({'true': 1, 'false': 0, 'yes': 1, 'no': 0}).fillna(df[col])\n",
    "\n",
    "# One-hot encode\n",
    "\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=False, dummy_na=False)\n",
    "print('After encoding:', df_encoded.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2e3a25",
   "metadata": {},
   "source": [
    "## 10) Build final feature matrices (raw + scaled)\n",
    "\n",
    "- Drop obvious identifiers & free-text\n",
    "- Keep numeric + engineered features + one-hot columns\n",
    "- Create scaled matrix for PCA/clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f23d4479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (8559, 68)\n",
      "Any NaNs in features? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yeow mun hung\\OneDrive\\Documents\\sdsdatathon\\.venv\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1207: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "c:\\Users\\yeow mun hung\\OneDrive\\Documents\\sdsdatathon\\.venv\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1212: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "c:\\Users\\yeow mun hung\\OneDrive\\Documents\\sdsdatathon\\.venv\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1236: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    }
   ],
   "source": [
    "# Drop identifier and free-text columns (keep only derived numeric/one-hot)\n",
    "id_cols = ['DUNS Number ', 'DUNS Number']\n",
    "text_cols = [\n",
    "    'Website', 'Address Line 1', 'City', 'State', 'State Or Province Abbreviation', 'Postal Code', 'Country', 'Phone Number',\n",
    "    'SIC Description', '8-Digit SIC Description', 'NAICS Description', 'NACE Rev 2 Description',\n",
    "    'ANZSIC Description', 'ISIC Rev 4 Description',\n",
    "    'Company Description',\n",
    "    'Parent Company', 'Parent Street Address', 'Parents City', 'Parent State/Province', 'Parent State/Province Abbreviation', 'Parent Postal Code', 'Parent Country/Region',\n",
    "    'Global Ultimate Company', 'Global Ultimate Street Address', 'Global Ultimate City Name', 'Global Ultimate State/Province', 'Ultimate State/Province Abbreviation', 'Global Ultimate Postal Code', 'Global Ultimate Country Name',\n",
    "    'Domestic Ultimate Company', 'Domestic Ultimate Street Address', 'Domestic Ultimate City Name', 'Domestic Ultimate State/Province Name', 'Domestic Ultimate State Abbreviation', 'Domestic Ultimate Postal Code',\n",
    "    'Registration Number',\n",
    "    status_col,\n",
    "]\n",
    "\n",
    "cols_to_drop = [c for c in (id_cols + text_cols) if c in df_encoded.columns]\n",
    "\n",
    "# Keep features\n",
    "\n",
    "df_features_raw = df_encoded.drop(columns=cols_to_drop)\n",
    "\n",
    "# Remove any remaining non-numeric columns (safety)\n",
    "df_features_raw = df_features_raw.select_dtypes(include=[np.number])\n",
    "\n",
    "print('Feature matrix shape:', df_features_raw.shape)\n",
    "\n",
    "# Scale for PCA/clustering\n",
    "scaler = StandardScaler()\n",
    "df_features_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(df_features_raw),\n",
    "    columns=df_features_raw.columns,\n",
    "    index=df_features_raw.index\n",
    ")\n",
    "\n",
    "# Quick check\n",
    "print('Any NaNs in features?', df_features_raw.isna().any().any())\n",
    "df_features_raw.to_csv(\"df_features_raw_member2.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1089a5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: nan_report_member2.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>nan_count</th>\n",
       "      <th>nan_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Company Sites</td>\n",
       "      <td>8559</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log_company_sites</td>\n",
       "      <td>8559</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ticker</td>\n",
       "      <td>8555</td>\n",
       "      <td>0.999533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANZSIC Code</td>\n",
       "      <td>7133</td>\n",
       "      <td>0.833392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NACE Rev 2 Code</td>\n",
       "      <td>7045</td>\n",
       "      <td>0.823110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ISIC Rev 4 Code</td>\n",
       "      <td>7045</td>\n",
       "      <td>0.823110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lattitude</td>\n",
       "      <td>6649</td>\n",
       "      <td>0.776843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Longitude</td>\n",
       "      <td>6647</td>\n",
       "      <td>0.776609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NAICS Code</td>\n",
       "      <td>5387</td>\n",
       "      <td>0.629396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8-Digit SIC Code</td>\n",
       "      <td>5309</td>\n",
       "      <td>0.620283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature_name  nan_count   nan_pct\n",
       "0      Company Sites       8559  1.000000\n",
       "1  log_company_sites       8559  1.000000\n",
       "2             Ticker       8555  0.999533\n",
       "3        ANZSIC Code       7133  0.833392\n",
       "4    NACE Rev 2 Code       7045  0.823110\n",
       "5    ISIC Rev 4 Code       7045  0.823110\n",
       "6          Lattitude       6649  0.776843\n",
       "7          Longitude       6647  0.776609\n",
       "8         NAICS Code       5387  0.629396\n",
       "9   8-Digit SIC Code       5309  0.620283"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Count missing values (NaNs) in each feature column\n",
    "nan_counts = df_features_raw.isna().sum()\n",
    "\n",
    "# 2) Keep only columns that actually have NaNs\n",
    "nan_counts = nan_counts[nan_counts > 0].sort_values(ascending=False)\n",
    "\n",
    "# 3) Convert into a clean table for export\n",
    "nan_report = nan_counts.reset_index()\n",
    "nan_report.columns = [\"feature_name\", \"nan_count\"]\n",
    "\n",
    "# 4) Add percentage of rows missing in each feature (easier to interpret)\n",
    "nan_report[\"nan_pct\"] = nan_report[\"nan_count\"] / len(df_features_raw)\n",
    "\n",
    "# 5) Save to CSV so I can inspect it\n",
    "nan_report.to_csv(\"nan_report_member2.csv\", index=False)\n",
    "\n",
    "print(\"Saved:\", \"nan_report_member2.csv\")\n",
    "nan_report.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f31cbb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with at least one NaN: 8559\n",
      "Saved: nan_rows_sample_member2.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Sites</th>\n",
       "      <th>log_company_sites</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>ANZSIC Code</th>\n",
       "      <th>NACE Rev 2 Code</th>\n",
       "      <th>ISIC Rev 4 Code</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>NAICS Code</th>\n",
       "      <th>8-Digit SIC Code</th>\n",
       "      <th>storage_devices_midpoint</th>\n",
       "      <th>servers_midpoint</th>\n",
       "      <th>it_spend_rate</th>\n",
       "      <th>routers_midpoint</th>\n",
       "      <th>it_spend_per_employee</th>\n",
       "      <th>log_it_assets_per_employee</th>\n",
       "      <th>log_it_spend_per_employee</th>\n",
       "      <th>it_assets_per_employee</th>\n",
       "      <th>company_age</th>\n",
       "      <th>Year Found</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3322.0</td>\n",
       "      <td>4672.0</td>\n",
       "      <td>4662.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>423510.0</td>\n",
       "      <td>50510000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2023.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.619889</td>\n",
       "      <td>5.5</td>\n",
       "      <td>173.600000</td>\n",
       "      <td>0.974560</td>\n",
       "      <td>5.162498</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2008.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.34088</td>\n",
       "      <td>123.96045</td>\n",
       "      <td>311411.0</td>\n",
       "      <td>20370000.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.619999</td>\n",
       "      <td>5.5</td>\n",
       "      <td>605.404494</td>\n",
       "      <td>0.501796</td>\n",
       "      <td>6.407547</td>\n",
       "      <td>0.651685</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.619993</td>\n",
       "      <td>5.5</td>\n",
       "      <td>29314.500000</td>\n",
       "      <td>2.862201</td>\n",
       "      <td>10.285872</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2011.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Company Sites  log_company_sites  Ticker  ANZSIC Code  NACE Rev 2 Code  \\\n",
       "0            NaN                NaN     NaN       3322.0           4672.0   \n",
       "1            NaN                NaN     NaN          NaN              NaN   \n",
       "2            NaN                NaN     NaN          NaN              NaN   \n",
       "3            NaN                NaN     NaN          NaN              NaN   \n",
       "4            NaN                NaN     NaN          NaN              NaN   \n",
       "\n",
       "   ISIC Rev 4 Code  Lattitude  Longitude  NAICS Code  8-Digit SIC Code  \\\n",
       "0           4662.0        NaN        NaN    423510.0        50510000.0   \n",
       "1              NaN        NaN        NaN         NaN               NaN   \n",
       "2              NaN   47.34088  123.96045    311411.0        20370000.0   \n",
       "3              NaN        NaN        NaN         NaN               NaN   \n",
       "4              NaN        NaN        NaN         NaN               NaN   \n",
       "\n",
       "   storage_devices_midpoint  servers_midpoint  it_spend_rate  \\\n",
       "0                       NaN               NaN            NaN   \n",
       "1                       5.5               5.5       0.619889   \n",
       "2                       5.5               5.5       0.619999   \n",
       "3                       NaN               NaN       0.619948   \n",
       "4                       5.5               5.5       0.619993   \n",
       "\n",
       "   routers_midpoint  it_spend_per_employee  log_it_assets_per_employee  \\\n",
       "0               5.5               0.000000                    3.135494   \n",
       "1               5.5             173.600000                    0.974560   \n",
       "2               5.5             605.404494                    0.501796   \n",
       "3               NaN                    NaN                         NaN   \n",
       "4               5.5           29314.500000                    2.862201   \n",
       "\n",
       "   log_it_spend_per_employee  it_assets_per_employee  company_age  Year Found  \n",
       "0                   0.000000               22.000000          3.0      2023.0  \n",
       "1                   5.162498                1.650000         18.0      2008.0  \n",
       "2                   6.407547                0.651685         13.0      2013.0  \n",
       "3                        NaN                     NaN         14.0      2012.0  \n",
       "4                  10.285872               16.500000         15.0      2011.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Identify which rows have ANY NaNs across the feature matrix\n",
    "rows_with_nan_mask = df_features_raw.isna().any(axis=1)\n",
    "\n",
    "# 2) Pull out the rows that have NaNs\n",
    "rows_with_nan = df_features_raw.loc[rows_with_nan_mask]\n",
    "\n",
    "print(\"Rows with at least one NaN:\", rows_with_nan.shape[0])\n",
    "\n",
    "# 3) Find the top 20 columns with the most NaNs (to focus the sample)\n",
    "top_nan_features = (\n",
    "    df_features_raw.isna().sum()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(20)\n",
    "    .index\n",
    ")\n",
    "\n",
    "# 4) Export a small sample (e.g., first 200 rows) of ONLY the top NaN columns\n",
    "nan_sample = rows_with_nan.loc[:, top_nan_features].head(200)\n",
    "\n",
    "# 5) Save to CSV for inspection\n",
    "nan_sample.to_csv(\"nan_rows_sample_member2.csv\", index=False)\n",
    "\n",
    "print(\"Saved:\", \"nan_rows_sample_member2.csv\")\n",
    "nan_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b8d51cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: feature_dtypes_member2.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Company Sites</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Employees Single Site</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Employees Total</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Revenue (USD)</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SIC Code</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature_name    dtype\n",
       "0          Company Sites  float64\n",
       "1  Employees Single Site  float64\n",
       "2        Employees Total    int64\n",
       "3          Revenue (USD)    int64\n",
       "4               SIC Code    int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Capture dtypes for every feature column\n",
    "feature_dtypes = df_features_raw.dtypes.astype(str).reset_index()\n",
    "feature_dtypes.columns = [\"feature_name\", \"dtype\"]\n",
    "\n",
    "# 2) Save\n",
    "feature_dtypes.to_csv(\"feature_dtypes_member2.csv\", index=False)\n",
    "\n",
    "print(\"Saved:\", \"feature_dtypes_member2.csv\")\n",
    "feature_dtypes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf79ad1",
   "metadata": {},
   "source": [
    "## 11) Export for Member 3 (optional)\n",
    "\n",
    "Uncomment to export once Member 1's clean_base.csv is ready.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0c298ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_features_raw.to_csv('data/processed/features_for_clustering_raw.csv', index=False)\n",
    "# df_features_scaled.to_csv('data/processed/features_for_clustering_scaled.csv', index=False)\n",
    "\n",
    "# Save feature list for handoff\n",
    "# pd.DataFrame({'feature': df_features_raw.columns}).to_csv('docs/feature_list_member2.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
