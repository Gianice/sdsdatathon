{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63f0b0fb",
   "metadata": {},
   "source": [
    "# Member 2 â€” Feature Engineering (Signal Construction)\n",
    "\n",
    "**Goal:** Turn company attributes into **numeric, comparable, explainable signals** for **PCA + clustering**.\n",
    "\n",
    "**Scope (Member 2):**\n",
    "- Start from **Member 1's cleaned & imputed dataset** (recommended: `data/processed/clean_base.csv`).\n",
    "- Do **not** make global cleaning decisions (dropping rows/columns, global imputation strategies, etc.).\n",
    "- You *may* create **presence indicators** and derived features that treat missingness as signal.\n",
    "\n",
    "**Outputs (for handoff):**\n",
    "- `df_features_raw`: numeric feature matrix (not scaled)\n",
    "- `df_features_scaled`: scaled matrix for PCA/clustering\n",
    "- `feature_dict`: short description of engineered features\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580538a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_columns', 250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a83d3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: ../data/champions_group_data.csv\n",
      "Shape: (8559, 72)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yeow mun hung\\AppData\\Local\\Temp\\ipykernel_9400\\1244267380.py:15: DtypeWarning: Columns (26,49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(RAW_FALLBACK)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Copy clean_base and load\n",
    "# -------------------------------\n",
    "ROOT = Path.cwd()\n",
    "if ROOT.name.lower() == \"notebooks\":\n",
    "    ROOT = ROOT.parent\n",
    "\n",
    "SOURCE_PATH = ROOT / \"modified_data\" / \"cleaned_base.csv\"\n",
    "DEST_DIR = ROOT / \"data\" / \"processed\"\n",
    "DEST_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CLEAN_PATH = DEST_DIR / \"clean_base.csv\"\n",
    "\n",
    "if not SOURCE_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Missing source file: {SOURCE_PATH}\")\n",
    "\n",
    "# Always copy to ensure an exact, unmodified clone\n",
    "shutil.copyfile(SOURCE_PATH, CLEAN_PATH)\n",
    "\n",
    "df = pd.read_csv(CLEAN_PATH)\n",
    "\n",
    "print(\"Copied clean_base.csv to:\", CLEAN_PATH)\n",
    "print(\"clean_base shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd6362f",
   "metadata": {},
   "source": [
    "## 1) Helper functions\n",
    "\n",
    "We standardize \"presence\" checks so empty strings don't count as filled.\n",
    "We also parse range strings like `\"1 to 10\"` into numeric midpoints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f63b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_value(series: pd.Series) -> pd.Series:\n",
    "    s = series.astype(\"string\").str.strip()\n",
    "    return s.notna() & s.ne(\"\")\n",
    "\n",
    "def normalize_text(series: pd.Series) -> pd.Series:\n",
    "    s = series.astype(\"string\").str.strip().str.upper()\n",
    "    return s.replace({\"\": pd.NA})\n",
    "\n",
    "def range_to_midpoint(value):\n",
    "    if isinstance(value, str):\n",
    "        if \"to\" in value:\n",
    "            parts = value.split(\"to\")\n",
    "        elif \"-\" in value:\n",
    "            parts = value.split(\"-\")\n",
    "        else:\n",
    "            return np.nan\n",
    "        if len(parts) >= 2:\n",
    "            try:\n",
    "                low = float(parts[0].strip())\n",
    "                high = float(parts[1].strip())\n",
    "                return (low + high) / 2\n",
    "            except ValueError:\n",
    "                return np.nan\n",
    "    return np.nan\n",
    "\n",
    "_split_re = re.compile(r\"[;,|]+\")\n",
    "\n",
    "def count_delimited_items(value) -> int:\n",
    "    if value is None:\n",
    "        return 0\n",
    "    if not isinstance(value, str):\n",
    "        value = str(value)\n",
    "    s = value.strip()\n",
    "    if s == \"\":\n",
    "        return 0\n",
    "    parts = [p.strip() for p in _split_re.split(s) if p.strip()]\n",
    "    return len(parts) if parts else 0\n",
    "\n",
    "def safe_to_numeric(series: pd.Series) -> pd.Series:\n",
    "    return pd.to_numeric(series, errors=\"coerce\")\n",
    "\n",
    "def add_numeric_feature(features: pd.DataFrame, series: pd.Series, name: str, log: bool = True):\n",
    "    series = safe_to_numeric(series)\n",
    "    missing = series.isna()\n",
    "    features[f\"{name}_missing\"] = missing.astype(int)\n",
    "    if series.notna().any():\n",
    "        fill_value = series.median()\n",
    "        series_filled = series.fillna(fill_value)\n",
    "    else:\n",
    "        series_filled = series.fillna(0)\n",
    "    features[name] = series_filled\n",
    "    if log:\n",
    "        features[f\"log_{name}\"] = np.log1p(series_filled.clip(lower=0))\n",
    "\n",
    "def missing_ratio_for(cols):\n",
    "    cols = [c for c in cols if c in df.columns]\n",
    "    if not cols:\n",
    "        return pd.Series(0, index=df.index)\n",
    "    present = {}\n",
    "    for c in cols:\n",
    "        s = df[c]\n",
    "        if pd.api.types.is_numeric_dtype(s):\n",
    "            present[c] = s.notna()\n",
    "        else:\n",
    "            present[c] = has_value(s)\n",
    "    present_df = pd.DataFrame(present)\n",
    "    return 1 - present_df.mean(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81d30dc",
   "metadata": {},
   "source": [
    "## 2) Core transparency + structure signals (curated short names)\n",
    "\n",
    "These are your **interpretable, low-risk** binary signals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6667ed8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(index=df.index)\n",
    "\n",
    "def add_has(col, feature_name):\n",
    "    if col in df.columns:\n",
    "        features[feature_name] = has_value(df[col]).astype(int)\n",
    "\n",
    "# Transparency / traceability\n",
    "add_has(\"Website\", \"has_website\")\n",
    "add_has(\"Phone Number\", \"has_phone\")\n",
    "add_has(\"Address Line 1\", \"has_address\")\n",
    "add_has(\"City\", \"has_city\")\n",
    "add_has(\"State\", \"has_state\")\n",
    "add_has(\"State Or Province Abbreviation\", \"has_state_abbrev\")\n",
    "add_has(\"Postal Code\", \"has_postal_code\")\n",
    "add_has(\"Country\", \"has_country\")\n",
    "add_has(\"Region\", \"has_region\")\n",
    "\n",
    "# Company name (column appears labeled as Company Sites in this dataset)\n",
    "add_has(\"Company Sites\", \"has_company_name\")\n",
    "\n",
    "# Ownership / structure\n",
    "add_has(\"Parent Company\", \"has_parent\")\n",
    "add_has(\"Global Ultimate Company\", \"has_global_ultimate\")\n",
    "add_has(\"Domestic Ultimate Company\", \"has_domestic_ultimate\")\n",
    "\n",
    "# Verifiability extras\n",
    "add_has(\"Ticker\", \"has_ticker\")\n",
    "add_has(\"Registration Number\", \"has_registration_number\")\n",
    "add_has(\"Company Description\", \"has_company_description\")\n",
    "add_has(\"Legal Status\", \"has_legal_status\")\n",
    "add_has(\"Ownership Type\", \"has_ownership_type\")\n",
    "add_has(\"Entity Type\", \"has_entity_type\")\n",
    "\n",
    "# Company status (value-coded)\n",
    "status_col = \"Company Status (Active/Inactive)\"\n",
    "if status_col in df.columns:\n",
    "    status = df[status_col].astype(\"string\").str.strip().str.lower()\n",
    "    status_map = {\"active\": 1, \"inactive\": 0}\n",
    "    features[\"company_status_binary\"] = status.map(status_map)\n",
    "    features[\"has_company_status\"] = features[\"company_status_binary\"].notna().astype(int)\n",
    "    features[\"company_status_binary\"] = features[\"company_status_binary\"].fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121dbe6f",
   "metadata": {},
   "source": [
    "## 3) Credibility / completeness score (and missing_ratio)\n",
    "\n",
    "We include **status-known** (not status value) so inactive firms aren't penalized.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0940bc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "credibility_flag_cols = [c for c in [\n",
    "    \"has_website\", \"has_address\", \"has_phone\",\n",
    "    \"has_ticker\", \"has_parent\", \"has_global_ultimate\", \"has_domestic_ultimate\",\n",
    "    \"has_registration_number\", \"has_company_description\",\n",
    "    \"has_company_status\"\n",
    "] if c in features.columns]\n",
    "\n",
    "if credibility_flag_cols:\n",
    "    features[\"credibility_score\"] = features[credibility_flag_cols].sum(axis=1)\n",
    "    features[\"credibility_score_norm\"] = features[\"credibility_score\"] / len(credibility_flag_cols)\n",
    "    features[\"missing_ratio_credibility\"] = 1 - features[\"credibility_score_norm\"]\n",
    "\n",
    "# Missingness ratios by group\n",
    "contact_cols = [\n",
    "    \"Website\", \"Phone Number\", \"Address Line 1\", \"City\", \"State\",\n",
    "    \"State Or Province Abbreviation\", \"Postal Code\", \"Country\", \"Region\"\n",
    "]\n",
    "ownership_cols = [\n",
    "    \"Parent Company\", \"Parent Country/Region\",\n",
    "    \"Global Ultimate Company\", \"Global Ultimate Country Name\",\n",
    "    \"Domestic Ultimate Company\"\n",
    "]\n",
    "financial_cols = [\n",
    "    \"Employees Single Site\", \"Employees Total\", \"Revenue (USD)\", \"Market Value (USD)\",\n",
    "    \"Corporate Family Members\", \"Year Found\"\n",
    "]\n",
    "it_cols = [\n",
    "    \"No. of PC\", \"No. of Desktops\", \"No. of Laptops\", \"No. of Routers\",\n",
    "    \"No. of Servers\", \"No. of Storage Devices\", \"IT Budget\", \"IT spend\"\n",
    "]\n",
    "code_cols = [\n",
    "    \"SIC Code\", \"8-Digit SIC Code\", \"NAICS Code\", \"NACE Rev 2 Code\",\n",
    "    \"ANZSIC Code\", \"ISIC Rev 4 Code\"\n",
    "]\n",
    "\n",
    "features[\"missing_ratio_contact\"] = missing_ratio_for(contact_cols)\n",
    "features[\"missing_ratio_ownership\"] = missing_ratio_for(ownership_cols)\n",
    "features[\"missing_ratio_financial\"] = missing_ratio_for(financial_cols)\n",
    "features[\"missing_ratio_it\"] = missing_ratio_for(it_cols)\n",
    "features[\"missing_ratio_codes\"] = missing_ratio_for(code_cols)\n",
    "\n",
    "all_missing_cols = contact_cols + ownership_cols + financial_cols + it_cols + code_cols\n",
    "features[\"missing_ratio_overall\"] = missing_ratio_for(all_missing_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e912d95",
   "metadata": {},
   "source": [
    "## 4) Organisational complexity (group size by global ultimate)\n",
    "\n",
    "Companies sharing the same global ultimate are treated as belonging to the same group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc1bc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"Global Ultimate Company\" in df.columns:\n",
    "    key = normalize_text(df[\"Global Ultimate Company\"])\n",
    "    group_sizes = key.groupby(key).transform(\"size\")\n",
    "    features[\"org_complexity_count\"] = group_sizes.fillna(0).astype(int)\n",
    "    features[\"log_org_complexity_count\"] = np.log1p(features[\"org_complexity_count\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e50d35",
   "metadata": {},
   "source": [
    "## 5) Scale + market signals\n",
    "\n",
    "These control for size so clustering isn't just \"big vs small\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47045713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coerce numeric fields and add log versions\n",
    "numeric_cols = {\n",
    "    \"Employees Total\": \"employees_total\",\n",
    "    \"Employees Single Site\": \"employees_single_site\",\n",
    "    \"Revenue (USD)\": \"revenue_usd\",\n",
    "    \"Market Value (USD)\": \"market_value_usd\",\n",
    "    \"Corporate Family Members\": \"corporate_family_members\",\n",
    "}\n",
    "\n",
    "for col, name in numeric_cols.items():\n",
    "    if col in df.columns:\n",
    "        add_numeric_feature(features, df[col], name, log=True)\n",
    "\n",
    "# Company age\n",
    "CURRENT_YEAR = 2026\n",
    "if \"Year Found\" in df.columns:\n",
    "    year_found = safe_to_numeric(df[\"Year Found\"])\n",
    "    company_age = CURRENT_YEAR - year_found\n",
    "    company_age = company_age.where((company_age >= 0) & (company_age <= 300))\n",
    "    features[\"company_age_missing\"] = company_age.isna().astype(int)\n",
    "    fill_value = company_age.median()\n",
    "    if pd.isna(fill_value):\n",
    "        fill_value = 0\n",
    "    company_age_filled = company_age.fillna(fill_value)\n",
    "    features[\"company_age\"] = company_age_filled\n",
    "    features[\"log_company_age\"] = np.log1p(company_age_filled.clip(lower=0))\n",
    "\n",
    "# Ratios\n",
    "if \"employees_total\" in features.columns and \"employees_single_site\" in features.columns:\n",
    "    denom = features[\"employees_total\"].replace(0, np.nan)\n",
    "    features[\"employee_concentration\"] = (features[\"employees_single_site\"] / denom).fillna(0)\n",
    "\n",
    "if \"revenue_usd\" in features.columns and \"employees_total\" in features.columns:\n",
    "    denom = features[\"employees_total\"].replace(0, np.nan)\n",
    "    features[\"revenue_per_employee\"] = (features[\"revenue_usd\"] / denom).fillna(0)\n",
    "\n",
    "if \"market_value_usd\" in features.columns and \"employees_total\" in features.columns:\n",
    "    denom = features[\"employees_total\"].replace(0, np.nan)\n",
    "    features[\"market_value_per_employee\"] = (features[\"market_value_usd\"] / denom).fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3332bd",
   "metadata": {},
   "source": [
    "## 6) Geography + multinational heuristics\n",
    "\n",
    "We avoid one-hot encoding high-cardinality city names. Use country/region + parent/ultimate country comparisons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105bf6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinates\n",
    "if \"Lattitude\" in df.columns:\n",
    "    add_numeric_feature(features, df[\"Lattitude\"], \"latitude\", log=False)\n",
    "\n",
    "if \"Longitude\" in df.columns:\n",
    "    add_numeric_feature(features, df[\"Longitude\"], \"longitude\", log=False)\n",
    "\n",
    "entity_country = normalize_text(df[\"Country\"]) if \"Country\" in df.columns else pd.Series(pd.NA, index=df.index)\n",
    "parent_country = normalize_text(df[\"Parent Country/Region\"]) if \"Parent Country/Region\" in df.columns else pd.Series(pd.NA, index=df.index)\n",
    "global_country = normalize_text(df[\"Global Ultimate Country Name\"]) if \"Global Ultimate Country Name\" in df.columns else pd.Series(pd.NA, index=df.index)\n",
    "\n",
    "parent_present = has_value(df[\"Parent Company\"]) if \"Parent Company\" in df.columns else pd.Series(False, index=df.index)\n",
    "global_present = has_value(df[\"Global Ultimate Company\"]) if \"Global Ultimate Company\" in df.columns else pd.Series(False, index=df.index)\n",
    "\n",
    "features[\"parent_foreign_flag\"] = (parent_present & parent_country.notna() & (parent_country != entity_country)).astype(int)\n",
    "features[\"global_ultimate_foreign_flag\"] = (global_present & global_country.notna() & (global_country != entity_country)).astype(int)\n",
    "features[\"multinational_flag\"] = ((features[\"parent_foreign_flag\"] == 1) | (features[\"global_ultimate_foreign_flag\"] == 1)).astype(int)\n",
    "\n",
    "countries_df = pd.concat([entity_country, parent_country, global_country], axis=1)\n",
    "features[\"num_countries_reported\"] = countries_df.nunique(axis=1, dropna=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14adc695",
   "metadata": {},
   "source": [
    "## 7) IT / operational footprint signals\n",
    "\n",
    "We parse IT asset ranges into midpoints, then build intensity & composition signals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175e80b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_range_or_numeric(value):\n",
    "    if isinstance(value, (int, float)) and not pd.isna(value):\n",
    "        return float(value)\n",
    "    if isinstance(value, str):\n",
    "        mid = range_to_midpoint(value)\n",
    "        if not pd.isna(mid):\n",
    "            return mid\n",
    "        try:\n",
    "            return float(value.strip())\n",
    "        except ValueError:\n",
    "            return np.nan\n",
    "    return np.nan\n",
    "\n",
    "asset_cols_map = {\n",
    "    \"No. of PC\": \"pc_midpoint\",\n",
    "    \"No. of Desktops\": \"desktops_midpoint\",\n",
    "    \"No. of Laptops\": \"laptops_midpoint\",\n",
    "    \"No. of Routers\": \"routers_midpoint\",\n",
    "    \"No. of Servers\": \"servers_midpoint\",\n",
    "    \"No. of Storage Devices\": \"storage_devices_midpoint\",\n",
    "}\n",
    "\n",
    "for col, name in asset_cols_map.items():\n",
    "    if col in df.columns:\n",
    "        series = df[col].apply(parse_range_or_numeric)\n",
    "        add_numeric_feature(features, series, name, log=True)\n",
    "\n",
    "asset_feature_cols = [name for name in asset_cols_map.values() if name in features.columns]\n",
    "if asset_feature_cols:\n",
    "    features[\"it_assets_total\"] = features[asset_feature_cols].sum(axis=1)\n",
    "    features[\"log_it_assets_total\"] = np.log1p(features[\"it_assets_total\"])\n",
    "\n",
    "if \"IT Budget\" in df.columns:\n",
    "    add_numeric_feature(features, df[\"IT Budget\"], \"it_budget\", log=True)\n",
    "if \"IT spend\" in df.columns:\n",
    "    add_numeric_feature(features, df[\"IT spend\"], \"it_spend\", log=True)\n",
    "\n",
    "if \"it_budget\" in features.columns and \"it_spend\" in features.columns:\n",
    "    denom = features[\"it_budget\"].replace(0, np.nan)\n",
    "    features[\"it_spend_rate\"] = (features[\"it_spend\"] / denom).fillna(0).clip(lower=0, upper=3)\n",
    "    features[\"it_budget_gap\"] = features[\"it_budget\"] - features[\"it_spend\"]\n",
    "    features[\"log_abs_it_budget_gap\"] = np.log1p(features[\"it_budget_gap\"].abs())\n",
    "\n",
    "if \"it_assets_total\" in features.columns and \"employees_total\" in features.columns:\n",
    "    denom = features[\"employees_total\"].replace(0, np.nan)\n",
    "    features[\"it_assets_per_employee\"] = (features[\"it_assets_total\"] / denom).fillna(0)\n",
    "\n",
    "if \"it_spend\" in features.columns and \"employees_total\" in features.columns:\n",
    "    denom = features[\"employees_total\"].replace(0, np.nan)\n",
    "    features[\"it_spend_per_employee\"] = (features[\"it_spend\"] / denom).fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed800dd",
   "metadata": {},
   "source": [
    "## 8) Industry code features (low-cardinality sector buckets)\n",
    "\n",
    "Full industry codes can be high-cardinality. For clustering/PCA, we use **2-digit buckets** (industry sectors).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8766c744",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_cols = {\n",
    "    \"SIC Code\": \"sic_code\",\n",
    "    \"8-Digit SIC Code\": \"sic8_code\",\n",
    "    \"NAICS Code\": \"naics_code\",\n",
    "    \"NACE Rev 2 Code\": \"nace2_code\",\n",
    "    \"ANZSIC Code\": \"anzsic_code\",\n",
    "    \"ISIC Rev 4 Code\": \"isic4_code\",\n",
    "}\n",
    "\n",
    "for col, prefix in code_cols.items():\n",
    "    if col in df.columns:\n",
    "        counts = df[col].astype(\"string\").apply(count_delimited_items)\n",
    "        features[f\"{prefix}_count\"] = counts\n",
    "        features[f\"has_{prefix}\"] = (counts > 0).astype(int)\n",
    "\n",
    "if \"Registration Number\" in df.columns:\n",
    "    reg_counts = df[\"Registration Number\"].astype(\"string\").apply(count_delimited_items)\n",
    "    features[\"registration_number_count\"] = reg_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b925e2b3",
   "metadata": {},
   "source": [
    "## 9) Categorical encoding (PCA/clustering ready)\n",
    "\n",
    "We one-hot encode selected low-cardinality categoricals + sector buckets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1af319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After encoding: (8559, 422)\n"
     ]
    }
   ],
   "source": [
    "bool_map = {\"true\": 1, \"false\": 0, \"yes\": 1, \"no\": 0, \"y\": 1, \"n\": 0, \"1\": 1, \"0\": 0}\n",
    "\n",
    "def add_boolean_feature(col, name):\n",
    "    if col not in df.columns:\n",
    "        return\n",
    "    s = df[col].astype(\"string\").str.strip().str.lower()\n",
    "    mapped = s.map(bool_map)\n",
    "    features[name] = mapped.fillna(0).astype(int)\n",
    "    features[f\"{name}_missing\"] = mapped.isna().astype(int)\n",
    "\n",
    "add_boolean_feature(\"Is Headquarters\", \"is_headquarters\")\n",
    "add_boolean_feature(\"Is Domestic Ultimate\", \"is_domestic_ultimate\")\n",
    "\n",
    "candidate_categoricals = [\n",
    "    \"Region\",\n",
    "    \"Entity Type\",\n",
    "    \"Ownership Type\",\n",
    "    \"Legal Status\",\n",
    "    \"Franchise Status\",\n",
    "    \"Manufacturing Status\",\n",
    "    \"Registration Number Type\",\n",
    "]\n",
    "\n",
    "categorical_cols = []\n",
    "for col in candidate_categoricals:\n",
    "    if col in df.columns and df[col].nunique(dropna=True) <= 20:\n",
    "        categorical_cols.append(col)\n",
    "\n",
    "if categorical_cols:\n",
    "    df_cats = df[categorical_cols].copy()\n",
    "    for col in categorical_cols:\n",
    "        df_cats[col] = df_cats[col].astype(\"string\").str.strip()\n",
    "    df_dummies = pd.get_dummies(df_cats, prefix=categorical_cols, prefix_sep=\"__\", dummy_na=True)\n",
    "else:\n",
    "    df_dummies = pd.DataFrame(index=df.index)\n",
    "\n",
    "print(\"Categorical columns encoded:\", categorical_cols)\n",
    "print(\"One-hot shape:\", df_dummies.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2e3a25",
   "metadata": {},
   "source": [
    "## 10) Build final feature matrices (raw + scaled)\n",
    "\n",
    "- Drop obvious identifiers & free-text\n",
    "- Keep numeric + engineered features + one-hot columns\n",
    "- Create scaled matrix for PCA/clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23d4479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (8559, 68)\n",
      "Any NaNs in features? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yeow mun hung\\OneDrive\\Documents\\sdsdatathon\\.venv\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1207: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "c:\\Users\\yeow mun hung\\OneDrive\\Documents\\sdsdatathon\\.venv\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1212: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "c:\\Users\\yeow mun hung\\OneDrive\\Documents\\sdsdatathon\\.venv\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1236: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    }
   ],
   "source": [
    "df_features_raw = pd.concat([features, df_dummies], axis=1)\n",
    "\n",
    "# Drop columns that are fully missing\n",
    "df_features_raw = df_features_raw.dropna(axis=1, how=\"all\")\n",
    "\n",
    "# Ensure numeric-only\n",
    "df_features_raw = df_features_raw.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "print(\"Feature matrix shape (pre-impute):\", df_features_raw.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1089a5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: nan_report_member2.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>nan_count</th>\n",
       "      <th>nan_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Company Sites</td>\n",
       "      <td>8559</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log_company_sites</td>\n",
       "      <td>8559</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ticker</td>\n",
       "      <td>8555</td>\n",
       "      <td>0.999533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANZSIC Code</td>\n",
       "      <td>7133</td>\n",
       "      <td>0.833392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NACE Rev 2 Code</td>\n",
       "      <td>7045</td>\n",
       "      <td>0.823110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ISIC Rev 4 Code</td>\n",
       "      <td>7045</td>\n",
       "      <td>0.823110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lattitude</td>\n",
       "      <td>6649</td>\n",
       "      <td>0.776843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Longitude</td>\n",
       "      <td>6647</td>\n",
       "      <td>0.776609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NAICS Code</td>\n",
       "      <td>5387</td>\n",
       "      <td>0.629396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8-Digit SIC Code</td>\n",
       "      <td>5309</td>\n",
       "      <td>0.620283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature_name  nan_count   nan_pct\n",
       "0      Company Sites       8559  1.000000\n",
       "1  log_company_sites       8559  1.000000\n",
       "2             Ticker       8555  0.999533\n",
       "3        ANZSIC Code       7133  0.833392\n",
       "4    NACE Rev 2 Code       7045  0.823110\n",
       "5    ISIC Rev 4 Code       7045  0.823110\n",
       "6          Lattitude       6649  0.776843\n",
       "7          Longitude       6647  0.776609\n",
       "8         NAICS Code       5387  0.629396\n",
       "9   8-Digit SIC Code       5309  0.620283"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix any remaining NaNs\n",
    "if df_features_raw.isna().any().any():\n",
    "    nan_cols = df_features_raw.columns[df_features_raw.isna().any()].tolist()\n",
    "    print(\"NaNs found in raw features. Top columns:\", nan_cols[:20])\n",
    "    for col in nan_cols:\n",
    "        series = df_features_raw[col]\n",
    "        fill_value = series.median()\n",
    "        if pd.isna(fill_value):\n",
    "            fill_value = 0\n",
    "        df_features_raw[col] = series.fillna(fill_value)\n",
    "\n",
    "assert not df_features_raw.isna().any().any(), \"NaNs remain in raw features\"\n",
    "\n",
    "# Scale for PCA/clustering\n",
    "scaler = StandardScaler()\n",
    "df_features_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(df_features_raw),\n",
    "    columns=df_features_raw.columns,\n",
    "    index=df_features_raw.index\n",
    ")\n",
    "\n",
    "assert not df_features_scaled.isna().any().any(), \"NaNs remain in scaled features\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31cbb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with at least one NaN: 8559\n",
      "Saved: nan_rows_sample_member2.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Sites</th>\n",
       "      <th>log_company_sites</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>ANZSIC Code</th>\n",
       "      <th>NACE Rev 2 Code</th>\n",
       "      <th>ISIC Rev 4 Code</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>NAICS Code</th>\n",
       "      <th>8-Digit SIC Code</th>\n",
       "      <th>storage_devices_midpoint</th>\n",
       "      <th>servers_midpoint</th>\n",
       "      <th>it_spend_rate</th>\n",
       "      <th>routers_midpoint</th>\n",
       "      <th>it_spend_per_employee</th>\n",
       "      <th>log_it_assets_per_employee</th>\n",
       "      <th>log_it_spend_per_employee</th>\n",
       "      <th>it_assets_per_employee</th>\n",
       "      <th>company_age</th>\n",
       "      <th>Year Found</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3322.0</td>\n",
       "      <td>4672.0</td>\n",
       "      <td>4662.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>423510.0</td>\n",
       "      <td>50510000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2023.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.619889</td>\n",
       "      <td>5.5</td>\n",
       "      <td>173.600000</td>\n",
       "      <td>0.974560</td>\n",
       "      <td>5.162498</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2008.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.34088</td>\n",
       "      <td>123.96045</td>\n",
       "      <td>311411.0</td>\n",
       "      <td>20370000.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.619999</td>\n",
       "      <td>5.5</td>\n",
       "      <td>605.404494</td>\n",
       "      <td>0.501796</td>\n",
       "      <td>6.407547</td>\n",
       "      <td>0.651685</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.619993</td>\n",
       "      <td>5.5</td>\n",
       "      <td>29314.500000</td>\n",
       "      <td>2.862201</td>\n",
       "      <td>10.285872</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2011.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Company Sites  log_company_sites  Ticker  ANZSIC Code  NACE Rev 2 Code  \\\n",
       "0            NaN                NaN     NaN       3322.0           4672.0   \n",
       "1            NaN                NaN     NaN          NaN              NaN   \n",
       "2            NaN                NaN     NaN          NaN              NaN   \n",
       "3            NaN                NaN     NaN          NaN              NaN   \n",
       "4            NaN                NaN     NaN          NaN              NaN   \n",
       "\n",
       "   ISIC Rev 4 Code  Lattitude  Longitude  NAICS Code  8-Digit SIC Code  \\\n",
       "0           4662.0        NaN        NaN    423510.0        50510000.0   \n",
       "1              NaN        NaN        NaN         NaN               NaN   \n",
       "2              NaN   47.34088  123.96045    311411.0        20370000.0   \n",
       "3              NaN        NaN        NaN         NaN               NaN   \n",
       "4              NaN        NaN        NaN         NaN               NaN   \n",
       "\n",
       "   storage_devices_midpoint  servers_midpoint  it_spend_rate  \\\n",
       "0                       NaN               NaN            NaN   \n",
       "1                       5.5               5.5       0.619889   \n",
       "2                       5.5               5.5       0.619999   \n",
       "3                       NaN               NaN       0.619948   \n",
       "4                       5.5               5.5       0.619993   \n",
       "\n",
       "   routers_midpoint  it_spend_per_employee  log_it_assets_per_employee  \\\n",
       "0               5.5               0.000000                    3.135494   \n",
       "1               5.5             173.600000                    0.974560   \n",
       "2               5.5             605.404494                    0.501796   \n",
       "3               NaN                    NaN                         NaN   \n",
       "4               5.5           29314.500000                    2.862201   \n",
       "\n",
       "   log_it_spend_per_employee  it_assets_per_employee  company_age  Year Found  \n",
       "0                   0.000000               22.000000          3.0      2023.0  \n",
       "1                   5.162498                1.650000         18.0      2008.0  \n",
       "2                   6.407547                0.651685         13.0      2013.0  \n",
       "3                        NaN                     NaN         14.0      2012.0  \n",
       "4                  10.285872               16.500000         15.0      2011.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_first_column(candidates):\n",
    "    for col in candidates:\n",
    "        if col in df.columns:\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "duns_col = None\n",
    "for col in df.columns:\n",
    "    if col.strip().lower() == \"duns number\":\n",
    "        duns_col = col\n",
    "        break\n",
    "\n",
    "name_col = find_first_column([\"Company Name\", \"Company\", \"Company Sites\"])\n",
    "\n",
    "row_id_map = pd.DataFrame({\"row_index\": df.index})\n",
    "if duns_col:\n",
    "    row_id_map[\"DUNS Number\"] = df[duns_col]\n",
    "if name_col:\n",
    "    row_id_map[\"Company Name\"] = df[name_col]\n",
    "\n",
    "print(\"Row id map columns:\", row_id_map.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8d51cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: feature_dtypes_member2.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Company Sites</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Employees Single Site</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Employees Total</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Revenue (USD)</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SIC Code</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature_name    dtype\n",
       "0          Company Sites  float64\n",
       "1  Employees Single Site  float64\n",
       "2        Employees Total    int64\n",
       "3          Revenue (USD)    int64\n",
       "4               SIC Code    int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_descriptions = {\n",
    "    \"has_website\": \"1 if Website is present\",\n",
    "    \"has_phone\": \"1 if Phone Number is present\",\n",
    "    \"has_address\": \"1 if Address Line 1 is present\",\n",
    "    \"has_city\": \"1 if City is present\",\n",
    "    \"has_state\": \"1 if State is present\",\n",
    "    \"has_state_abbrev\": \"1 if State Or Province Abbreviation is present\",\n",
    "    \"has_postal_code\": \"1 if Postal Code is present\",\n",
    "    \"has_country\": \"1 if Country is present\",\n",
    "    \"has_region\": \"1 if Region is present\",\n",
    "    \"has_company_name\": \"1 if Company Sites (company name) is present\",\n",
    "    \"has_parent\": \"1 if Parent Company is present\",\n",
    "    \"has_global_ultimate\": \"1 if Global Ultimate Company is present\",\n",
    "    \"has_domestic_ultimate\": \"1 if Domestic Ultimate Company is present\",\n",
    "    \"has_ticker\": \"1 if Ticker is present\",\n",
    "    \"has_registration_number\": \"1 if Registration Number is present\",\n",
    "    \"has_company_description\": \"1 if Company Description is present\",\n",
    "    \"has_legal_status\": \"1 if Legal Status is present\",\n",
    "    \"has_ownership_type\": \"1 if Ownership Type is present\",\n",
    "    \"has_entity_type\": \"1 if Entity Type is present\",\n",
    "    \"company_status_binary\": \"1 if Company Status is active, 0 if inactive or missing\",\n",
    "    \"has_company_status\": \"1 if Company Status is present\",\n",
    "    \"credibility_score\": \"Count of core transparency/ownership flags present\",\n",
    "    \"credibility_score_norm\": \"Credibility score normalized by number of flags\",\n",
    "    \"missing_ratio_credibility\": \"1 - credibility_score_norm\",\n",
    "    \"missing_ratio_contact\": \"Missing ratio across contact fields\",\n",
    "    \"missing_ratio_ownership\": \"Missing ratio across ownership fields\",\n",
    "    \"missing_ratio_financial\": \"Missing ratio across financial fields\",\n",
    "    \"missing_ratio_it\": \"Missing ratio across IT fields\",\n",
    "    \"missing_ratio_codes\": \"Missing ratio across industry code fields\",\n",
    "    \"missing_ratio_overall\": \"Missing ratio across key groups\",\n",
    "    \"org_complexity_count\": \"Count of entities sharing the same global ultimate\",\n",
    "    \"log_org_complexity_count\": \"log1p of org_complexity_count\",\n",
    "    \"employees_total\": \"Employees total (imputed)\",\n",
    "    \"employees_single_site\": \"Employees single site (imputed)\",\n",
    "    \"revenue_usd\": \"Revenue USD (imputed)\",\n",
    "    \"market_value_usd\": \"Market value USD (imputed)\",\n",
    "    \"corporate_family_members\": \"Corporate family members (imputed)\",\n",
    "    \"company_age\": \"Company age in years (imputed)\",\n",
    "    \"employee_concentration\": \"Employees single site divided by employees total\",\n",
    "    \"revenue_per_employee\": \"Revenue per employee (USD)\",\n",
    "    \"market_value_per_employee\": \"Market value per employee (USD)\",\n",
    "    \"latitude\": \"Latitude (imputed)\",\n",
    "    \"longitude\": \"Longitude (imputed)\",\n",
    "    \"parent_foreign_flag\": \"1 if parent country differs from entity country\",\n",
    "    \"global_ultimate_foreign_flag\": \"1 if global ultimate country differs from entity country\",\n",
    "    \"multinational_flag\": \"1 if parent or global ultimate is foreign\",\n",
    "    \"num_countries_reported\": \"Count of unique countries reported (entity/parent/global)\",\n",
    "    \"pc_midpoint\": \"Midpoint of PC count range (imputed)\",\n",
    "    \"desktops_midpoint\": \"Midpoint of desktop count range (imputed)\",\n",
    "    \"laptops_midpoint\": \"Midpoint of laptop count range (imputed)\",\n",
    "    \"routers_midpoint\": \"Midpoint of router count range (imputed)\",\n",
    "    \"servers_midpoint\": \"Midpoint of server count range (imputed)\",\n",
    "    \"storage_devices_midpoint\": \"Midpoint of storage device count range (imputed)\",\n",
    "    \"it_assets_total\": \"Sum of IT asset midpoints\",\n",
    "    \"log_it_assets_total\": \"log1p of it_assets_total\",\n",
    "    \"it_budget\": \"IT budget (imputed)\",\n",
    "    \"it_spend\": \"IT spend (imputed)\",\n",
    "    \"it_spend_rate\": \"IT spend divided by IT budget (clipped)\",\n",
    "    \"it_budget_gap\": \"IT budget minus IT spend\",\n",
    "    \"log_abs_it_budget_gap\": \"log1p of absolute IT budget gap\",\n",
    "    \"it_assets_per_employee\": \"IT assets per employee\",\n",
    "    \"it_spend_per_employee\": \"IT spend per employee\",\n",
    "    \"sic_code_count\": \"Number of SIC codes (split on delimiters)\",\n",
    "    \"sic8_code_count\": \"Number of 8-digit SIC codes (split on delimiters)\",\n",
    "    \"naics_code_count\": \"Number of NAICS codes (split on delimiters)\",\n",
    "    \"nace2_code_count\": \"Number of NACE Rev 2 codes (split on delimiters)\",\n",
    "    \"anzsic_code_count\": \"Number of ANZSIC codes (split on delimiters)\",\n",
    "    \"isic4_code_count\": \"Number of ISIC Rev 4 codes (split on delimiters)\",\n",
    "    \"has_sic_code\": \"1 if SIC Code is present\",\n",
    "    \"has_sic8_code\": \"1 if 8-digit SIC Code is present\",\n",
    "    \"has_naics_code\": \"1 if NAICS Code is present\",\n",
    "    \"has_nace2_code\": \"1 if NACE Rev 2 Code is present\",\n",
    "    \"has_anzsic_code\": \"1 if ANZSIC Code is present\",\n",
    "    \"has_isic4_code\": \"1 if ISIC Rev 4 Code is present\",\n",
    "    \"registration_number_count\": \"Number of registration numbers (split on delimiters)\",\n",
    "}\n",
    "\n",
    "def describe_feature(name):\n",
    "    if name in feature_descriptions:\n",
    "        return feature_descriptions[name]\n",
    "    if name.endswith(\"_missing\"):\n",
    "        base = name[:-8]\n",
    "        return f\"Missing indicator for {base}\"\n",
    "    if name.startswith(\"log_\"):\n",
    "        base = name[4:]\n",
    "        return f\"log1p of {base}\"\n",
    "    if \"__\" in name:\n",
    "        base, val = name.split(\"__\", 1)\n",
    "        val_norm = val.strip().lower()\n",
    "        if val_norm in (\"nan\", \"<na>\"):\n",
    "            return f\"Missing indicator for {base}\"\n",
    "        return f\"One-hot: {base} = {val}\"\n",
    "    return \"Derived numeric feature\"\n",
    "\n",
    "feature_dict = pd.DataFrame({\n",
    "    \"feature\": df_features_raw.columns,\n",
    "    \"description\": [describe_feature(c) for c in df_features_raw.columns],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf79ad1",
   "metadata": {},
   "source": [
    "## 11) Export for Member 3 (optional)\n",
    "\n",
    "Uncomment to export once Member 1's clean_base.csv is ready.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c298ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = DEST_DIR\n",
    "DOCS_DIR = ROOT / \"docs\"\n",
    "DOCS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "features_raw_path = OUTPUT_DIR / \"features_for_clustering_raw.csv\"\n",
    "features_scaled_path = OUTPUT_DIR / \"features_for_clustering_scaled.csv\"\n",
    "row_id_map_path = OUTPUT_DIR / \"row_id_map.csv\"\n",
    "feature_dict_path = DOCS_DIR / \"feature_dictionary_member2.csv\"\n",
    "\n",
    "df_features_raw.to_csv(features_raw_path, index=False)\n",
    "df_features_scaled.to_csv(features_scaled_path, index=False)\n",
    "row_id_map.to_csv(row_id_map_path, index=False)\n",
    "feature_dict.to_csv(feature_dict_path, index=False)\n",
    "\n",
    "print(\"Saved:\", features_raw_path)\n",
    "print(\"Saved:\", features_scaled_path)\n",
    "print(\"Saved:\", row_id_map_path)\n",
    "print(\"Saved:\", feature_dict_path)\n",
    "\n",
    "print(\"clean_base shape:\", df.shape)\n",
    "print(\"Raw features shape:\", df_features_raw.shape)\n",
    "print(\"Scaled features shape:\", df_features_scaled.shape)\n",
    "print(\"Any NaNs in raw features?\", df_features_raw.isna().any().any())\n",
    "print(\"Any NaNs in scaled features?\", df_features_scaled.isna().any().any())\n",
    "print(\"Number of feature columns:\", df_features_raw.shape[1])\n",
    "\n",
    "assert df_features_raw.shape[0] == df.shape[0]\n",
    "assert df_features_scaled.shape[0] == df.shape[0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
